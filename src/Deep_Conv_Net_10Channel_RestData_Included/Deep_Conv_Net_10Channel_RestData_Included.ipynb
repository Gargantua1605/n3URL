{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prakhar n Sankalp\n",
    "right = np.loadtxt(\"right_data.txt\")\n",
    "right_C_1=np.loadtxt(\"right_data_C_1.txt\")\n",
    "right_C_3=np.loadtxt(\"right_data_C_3.txt\")\n",
    "right_CP_1 = np.loadtxt(\"right_data_CP_1.txt\")\n",
    "right_CP_3 = np.loadtxt(\"right_data_CP_3.txt\")\n",
    "left = np.loadtxt(\"left_data.txt\")\n",
    "left_C_1=np.loadtxt(\"left_data_C_1.txt\")\n",
    "left_C_3=np.loadtxt(\"left_data_C_3.txt\")\n",
    "left_CP_1 = np.loadtxt(\"left_data_CP_1.txt\")\n",
    "left_CP_3 = np.loadtxt(\"left_data_CP_3.txt\")\n",
    "\n",
    "rest=np.loadtxt(\"rest_data.txt\")\n",
    "rest_C_1=np.loadtxt(\"rest_data_C_1.txt\")\n",
    "rest_C_3=np.loadtxt(\"rest_data_C_3.txt\")\n",
    "rest_CP_1 = np.loadtxt(\"rest_data_CP_1.txt\")\n",
    "rest_CP_3 = np.loadtxt(\"rest_data_CP_3.txt\")\n",
    "\n",
    "\n",
    "right_reshaped = np.reshape(right, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_reshaped = np.reshape(left, (left.shape[0], left.shape[1] // 2, 2))\n",
    "rest_reshaped= np.reshape(rest, (rest.shape[0], rest.shape[1] // 2, 2))\n",
    "\n",
    "right_C_1_reshaped = np.reshape(right_C_1, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_C_1_reshaped = np.reshape(left_C_1, (left.shape[0], left.shape[1] // 2, 2))\n",
    "rest_C_1_reshaped= np.reshape(rest_C_1, (rest_C_1.shape[0], rest_C_1.shape[1] // 2, 2))\n",
    "\n",
    "right_C_3_reshaped = np.reshape(right_C_3, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_C_3_reshaped = np.reshape(left_C_3, (left.shape[0], left.shape[1] // 2, 2))\n",
    "rest_C_3_reshaped= np.reshape(rest_C_3, (rest_C_3.shape[0], rest_C_3.shape[1] // 2, 2))\n",
    "\n",
    "right_CP_1_reshaped = np.reshape(right_CP_1, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_CP_1_reshaped = np.reshape(left_CP_1, (left.shape[0], left.shape[1] // 2, 2))\n",
    "rest_CP_1_reshaped= np.reshape(rest_CP_1, (rest_CP_1.shape[0], rest_CP_1.shape[1] // 2, 2))\n",
    "\n",
    "right_CP_3_reshaped = np.reshape(right_CP_3, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_CP_3_reshaped = np.reshape(left_CP_3, (left.shape[0], left.shape[1] // 2, 2))\n",
    "\n",
    "rest_CP_3_reshaped= np.reshape(rest_CP_3, (rest_CP_3.shape[0], rest_CP_3.shape[1] // 2, 2))\n",
    "\n",
    "right_label = np.zeros((right.shape[0], 2))\n",
    "right_label[:,0] = 1\n",
    "left_label = np.zeros((left.shape[0], 2))\n",
    "left_label[:, 1] = 1\n",
    "\n",
    "rest_label=np.zeros((rest.shape[0],2))\n",
    "\n",
    "\n",
    "\n",
    "right_train=right_reshaped[:int(0.8*2352)]\n",
    "right_C_1_train=right_C_1_reshaped[:int(0.8*2352)]\n",
    "right_C_3_train=right_C_3_reshaped[:int(0.8*2352)]\n",
    "right_CP_1_train=right_CP_1_reshaped[:int(0.8*2352)]\n",
    "right_CP_3_train=right_CP_3_reshaped[:int(0.8*2352)]\n",
    "\n",
    "right_test=right_reshaped[int(0.8*2352):]\n",
    "right_C_1_test=right_C_1_reshaped[int(0.8*2352):]\n",
    "right_C_3_test=right_C_3_reshaped[int(0.8*2352):]\n",
    "right_CP_1_test=right_CP_1_reshaped[int(0.8*2352):]\n",
    "right_CP_3_test=right_CP_3_reshaped[int(0.8*2352):]\n",
    "\n",
    "\n",
    "right_label_train=right_label[:int(0.8*2352)]\n",
    "right_label_test=right_label[int(0.8*2352):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "left_train=left_reshaped[:int(0.8*2396)]\n",
    "left_C_1_train=left_C_1_reshaped[:int(0.8*2396)]\n",
    "left_C_3_train=left_C_3_reshaped[:int(0.8*2396)]\n",
    "left_CP_1_train=left_CP_1_reshaped[:int(0.8*2396)]\n",
    "left_CP_3_train=left_CP_3_reshaped[:int(0.8*2396)]\n",
    "\n",
    "left_test=left_reshaped[int(0.8*2396):]\n",
    "left_C_1_test=left_C_1_reshaped[int(0.8*2396):]\n",
    "left_C_3_test=left_C_3_reshaped[int(0.8*2396):]\n",
    "left_CP_1_test=left_CP_1_reshaped[int(0.8*2396):]\n",
    "left_CP_3_test=left_CP_3_reshaped[int(0.8*2396):]\n",
    "\n",
    "\n",
    "\n",
    "left_label_train=left_label[:int(0.8*2396)]\n",
    "left_label_test=left_label[int(0.8*2396):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train=rest_reshaped[:int(0.8*4768)]\n",
    "rest_C_1_train=rest_C_1_reshaped[:int(0.8*4768)]\n",
    "rest_C_3_train=rest_C_3_reshaped[:int(0.8*4768)]\n",
    "rest_CP_1_train=rest_CP_1_reshaped[:int(0.8*4768)]\n",
    "rest_CP_3_train=rest_CP_3_reshaped[:int(0.8*4768)]\n",
    "\n",
    "rest_test=rest_reshaped[int(0.8*4768):]\n",
    "rest_C_1_test=rest_C_1_reshaped[int(0.8*4768):]\n",
    "rest_C_3_test=rest_C_3_reshaped[int(0.8*4768):]\n",
    "rest_CP_1_test=rest_CP_1_reshaped[int(0.8*4768):]\n",
    "rest_CP_3_test=rest_CP_3_reshaped[int(0.8*4768):]\n",
    "\n",
    "\n",
    "rest_label_train=rest_label[:int(0.8*4768)]\n",
    "rest_label_test=rest_label[int(0.8*4768):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7611, 640, 10)\n",
      "(7611, 2)\n",
      "(1905, 640, 10)\n"
     ]
    }
   ],
   "source": [
    "data_train=np.concatenate((right_train, left_train,rest_train), axis = 0)\n",
    "data_train_C_1= np.concatenate((right_C_1_train, left_C_1_train,rest_C_1_train), axis = 0)\n",
    "data_train_C_3=np.concatenate((right_C_3_train, left_C_3_train,rest_C_3_train), axis = 0)\n",
    "data_train_CP_1= np.concatenate((right_CP_1_train, left_CP_1_train,rest_CP_1_train), axis = 0)\n",
    "data_train_CP_3=np.concatenate((right_CP_3_train, left_CP_3_train,rest_CP_3_train), axis = 0)\n",
    "data_final_train=np.concatenate((data_train,data_train_C_1,data_train_C_3, data_train_CP_1, data_train_CP_3), axis = 2)\n",
    "\n",
    "data_test=np.concatenate((right_test, left_test,rest_test), axis = 0)\n",
    "data_test_C_1= np.concatenate((right_C_1_test, left_C_1_test,rest_C_1_test), axis = 0)\n",
    "data_test_C_3=np.concatenate((right_C_3_test, left_C_3_test,rest_C_3_test), axis = 0)\n",
    "data_test_CP_1= np.concatenate((right_CP_1_test, left_CP_1_test,rest_CP_1_test), axis = 0)\n",
    "data_test_CP_3=np.concatenate((right_CP_3_test, left_CP_3_test,rest_CP_3_test), axis = 0)\n",
    "data_final_test=np.concatenate((data_test,data_test_C_1,data_test_C_3, data_test_CP_1, data_test_CP_3), axis = 2)\n",
    "\n",
    "label_train = np.concatenate((right_label_train, left_label_train,rest_label_train), axis = 0)\n",
    "label_test = np.concatenate((right_label_test, left_label_test,rest_label_test), axis = 0)\n",
    "\n",
    "print(data_final_train.shape)\n",
    "print(label_train.shape)\n",
    "\n",
    "print(data_final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize_1= np.arange(0, data_final_train.shape[0], 1)\n",
    "randomize_1 = np.random.permutation(randomize_1)\n",
    "\n",
    "randomize_2= np.arange(0, data_final_test.shape[0], 1)\n",
    "randomize_2 = np.random.permutation(randomize_2)\n",
    "\n",
    "data_final_train = data_final_train[randomize_1]\n",
    "label_train = label_train[randomize_1]\n",
    "data_final_test = data_final_test[randomize_2]\n",
    "label_test = label_test[randomize_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "def new_model(nb_classes, Chans, Samples, dropoutRate = 0.5):\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as tfl\n",
    "model = new_model(2, 10, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 640, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 10, 636, 25)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 636, 25)        6275      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 636, 25)        100       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 636, 25)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 318, 25)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 318, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 314, 50)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 314, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 314, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 157, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 157, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 153, 100)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 153, 100)       400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 153, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 76, 100)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 76, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 72, 200)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 72, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 72, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 36, 200)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 36, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 14402     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 153,927\n",
      "Trainable params: 153,177\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=keras.losses.BinaryCrossentropy(), metrics=keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7611, 10, 640)\n"
     ]
    }
   ],
   "source": [
    "data_fin_train = data_final_train[0].T\n",
    "data_fin_test = data_final_test[0].T\n",
    "data_fin_train = np.concatenate((np.array([data_fin_train]), np.array([data_final_train[1].T])), axis = 0)\n",
    "data_fin_test = np.concatenate((np.array([data_fin_test]), np.array([data_final_test[1].T])), axis = 0)\n",
    "for i in data_final_train[2:]:\n",
    "    data_fin_train = np.concatenate((np.array(data_fin_train), np.array([i.T])), axis = 0)\n",
    "for j in data_final_test[2:]:    \n",
    "    data_fin_test = np.concatenate((np.array(data_fin_test), np.array([j.T])), axis = 0)\n",
    "print(data_fin_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 60s 38ms/step - loss: 0.6148 - binary_accuracy: 0.5050\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 64s 42ms/step - loss: 0.5602 - binary_accuracy: 0.5256\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 75s 49ms/step - loss: 0.5324 - binary_accuracy: 0.5363\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 65s 42ms/step - loss: 0.5211 - binary_accuracy: 0.5380\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 64s 42ms/step - loss: 0.4883 - binary_accuracy: 0.5517\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 64s 42ms/step - loss: 0.4761 - binary_accuracy: 0.5689\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 68s 45ms/step - loss: 0.4576 - binary_accuracy: 0.5710\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 68s 45ms/step - loss: 0.4499 - binary_accuracy: 0.5747\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 66s 43ms/step - loss: 0.4480 - binary_accuracy: 0.5774\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 59s 39ms/step - loss: 0.4460 - binary_accuracy: 0.5800\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.4424 - binary_accuracy: 0.5792\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 60s 39ms/step - loss: 0.4292 - binary_accuracy: 0.5941\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 62s 41ms/step - loss: 0.4238 - binary_accuracy: 0.5871\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 61s 40ms/step - loss: 0.4160 - binary_accuracy: 0.5934\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 64s 42ms/step - loss: 0.4178 - binary_accuracy: 0.5830\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 61s 40ms/step - loss: 0.4114 - binary_accuracy: 0.5969\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 62s 41ms/step - loss: 0.4096 - binary_accuracy: 0.5858\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 61s 40ms/step - loss: 0.4031 - binary_accuracy: 0.5997\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 60s 40ms/step - loss: 0.4061 - binary_accuracy: 0.5911\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 62s 41ms/step - loss: 0.4135 - binary_accuracy: 0.5869\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 61s 40ms/step - loss: 0.4024 - binary_accuracy: 0.5896\n",
      "Epoch 22/25\n",
      "1523/1523 [==============================] - 65s 43ms/step - loss: 0.4074 - binary_accuracy: 0.5984\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 68s 45ms/step - loss: 0.3934 - binary_accuracy: 0.5954\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 70s 46ms/step - loss: 0.4000 - binary_accuracy: 0.5885\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 52s 34ms/step - loss: 0.3939 - binary_accuracy: 0.6070\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.6442 - binary_accuracy: 0.6084\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3952 - binary_accuracy: 0.5928\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 52s 34ms/step - loss: 0.3930 - binary_accuracy: 0.5987\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 57s 37ms/step - loss: 0.3931 - binary_accuracy: 0.5949 0s - loss: 0.3931 - binary_accuracy: \n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 54s 36ms/step - loss: 0.3884 - binary_accuracy: 0.6014\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 54s 35ms/step - loss: 0.3875 - binary_accuracy: 0.6035\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 53s 35ms/step - loss: 0.3901 - binary_accuracy: 0.5966\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 55s 36ms/step - loss: 0.3899 - binary_accuracy: 0.5928\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 53s 35ms/step - loss: 0.3820 - binary_accuracy: 0.5981\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 55s 36ms/step - loss: 0.3822 - binary_accuracy: 0.6004\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 51s 34ms/step - loss: 0.3817 - binary_accuracy: 0.5986\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 53s 35ms/step - loss: 0.3827 - binary_accuracy: 0.5943\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 51s 33ms/step - loss: 0.3762 - binary_accuracy: 0.6015\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 56s 37ms/step - loss: 0.3848 - binary_accuracy: 0.5989\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 56s 37ms/step - loss: 0.3782 - binary_accuracy: 0.6020\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 54s 35ms/step - loss: 0.3813 - binary_accuracy: 0.5966\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 50s 33ms/step - loss: 0.3807 - binary_accuracy: 0.6018 1s - loss: 0.3\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 50s 33ms/step - loss: 0.3805 - binary_accuracy: 0.5987\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 52s 34ms/step - loss: 0.3754 - binary_accuracy: 0.6033\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 50s 33ms/step - loss: 0.3757 - binary_accuracy: 0.5991\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 51s 34ms/step - loss: 0.3739 - binary_accuracy: 0.6010\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 42s 27ms/step - loss: 0.3728 - binary_accuracy: 0.6037\n",
      "Epoch 22/25\n",
      "1523/1523 [==============================] - 35s 23ms/step - loss: 0.3704 - binary_accuracy: 0.5990\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3744 - binary_accuracy: 0.5981\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3675 - binary_accuracy: 0.6029\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3697 - binary_accuracy: 0.6078\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.8572 - binary_accuracy: 0.6073\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 35s 23ms/step - loss: 0.3667 - binary_accuracy: 0.6016\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3657 - binary_accuracy: 0.6012\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3650 - binary_accuracy: 0.6054\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3666 - binary_accuracy: 0.6004\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3694 - binary_accuracy: 0.6002\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3733 - binary_accuracy: 0.6019\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3687 - binary_accuracy: 0.5995\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 41s 27ms/step - loss: 0.3662 - binary_accuracy: 0.6008\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3667 - binary_accuracy: 0.5995\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3614 - binary_accuracy: 0.6043\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3602 - binary_accuracy: 0.6052\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3607 - binary_accuracy: 0.6028\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3606 - binary_accuracy: 0.6054\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3598 - binary_accuracy: 0.6039\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3629 - binary_accuracy: 0.6052\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3611 - binary_accuracy: 0.6037\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3575 - binary_accuracy: 0.6029\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3564 - binary_accuracy: 0.6045 2s -\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3565 - binary_accuracy: 0.6068\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3517 - binary_accuracy: 0.6104\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3613 - binary_accuracy: 0.6047\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3540 - binary_accuracy: 0.6100\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 40s 27ms/step - loss: 0.3563 - binary_accuracy: 0.6037\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3546 - binary_accuracy: 0.6058\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3564 - binary_accuracy: 0.6074\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.5311 - binary_accuracy: 0.6089\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3565 - binary_accuracy: 0.6048\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3535 - binary_accuracy: 0.6069\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3535 - binary_accuracy: 0.6085\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3540 - binary_accuracy: 0.6035\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 36s 23ms/step - loss: 0.3490 - binary_accuracy: 0.6087\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3497 - binary_accuracy: 0.6092\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3482 - binary_accuracy: 0.6073\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 35s 23ms/step - loss: 0.3473 - binary_accuracy: 0.6047\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 36s 23ms/step - loss: 0.3497 - binary_accuracy: 0.6039\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3469 - binary_accuracy: 0.6127\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3473 - binary_accuracy: 0.6074\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3456 - binary_accuracy: 0.6056\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3496 - binary_accuracy: 0.6081\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3475 - binary_accuracy: 0.6065\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3502 - binary_accuracy: 0.6081\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3515 - binary_accuracy: 0.6079\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3474 - binary_accuracy: 0.6111\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3475 - binary_accuracy: 0.6083\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 36s 24ms/step - loss: 0.3410 - binary_accuracy: 0.6104\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3431 - binary_accuracy: 0.6116\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3461 - binary_accuracy: 0.6124\n",
      "Epoch 22/25\n",
      "1523/1523 [==============================] - 43s 28ms/step - loss: 0.3432 - binary_accuracy: 0.6163\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 61s 40ms/step - loss: 0.3395 - binary_accuracy: 0.6150\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 59s 39ms/step - loss: 0.3433 - binary_accuracy: 0.6129\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 60s 39ms/step - loss: 0.3413 - binary_accuracy: 0.6128\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 1.1039 - binary_accuracy: 0.6047\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 63s 42ms/step - loss: 0.3453 - binary_accuracy: 0.6099\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 65s 43ms/step - loss: 0.3404 - binary_accuracy: 0.6140\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 59s 38ms/step - loss: 0.3462 - binary_accuracy: 0.6087\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3404 - binary_accuracy: 0.6112\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 59s 39ms/step - loss: 0.3397 - binary_accuracy: 0.6135\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3371 - binary_accuracy: 0.6128\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3347 - binary_accuracy: 0.6145\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3417 - binary_accuracy: 0.6114 2s - loss: 0\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 64s 42ms/step - loss: 0.3380 - binary_accuracy: 0.6145\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3395 - binary_accuracy: 0.6117\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 58s 38ms/step - loss: 0.3360 - binary_accuracy: 0.6199\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 57s 38ms/step - loss: 0.3359 - binary_accuracy: 0.6133\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 46s 30ms/step - loss: 0.3402 - binary_accuracy: 0.6120\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3345 - binary_accuracy: 0.6148\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 36s 23ms/step - loss: 0.3342 - binary_accuracy: 0.6158\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 35s 23ms/step - loss: 0.3348 - binary_accuracy: 0.6178\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 36s 23ms/step - loss: 0.3354 - binary_accuracy: 0.6149\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3369 - binary_accuracy: 0.6117 2s -\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3381 - binary_accuracy: 0.6160\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3413 - binary_accuracy: 0.6149\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 43s 28ms/step - loss: 0.3279 - binary_accuracy: 0.6191\n",
      "Epoch 22/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3357 - binary_accuracy: 0.6127\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3291 - binary_accuracy: 0.6194\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3320 - binary_accuracy: 0.6190 4s - l - ETA: 2s\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3273 - binary_accuracy: 0.6177\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 1.7009 - binary_accuracy: 0.6115\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3335 - binary_accuracy: 0.6158\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3285 - binary_accuracy: 0.6153\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3349 - binary_accuracy: 0.6125\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3305 - binary_accuracy: 0.6128\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3278 - binary_accuracy: 0.6171\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3318 - binary_accuracy: 0.6166\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3261 - binary_accuracy: 0.6198\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3263 - binary_accuracy: 0.6234\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3304 - binary_accuracy: 0.6178\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3260 - binary_accuracy: 0.6161\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3283 - binary_accuracy: 0.6199 1s - loss: 0.3275 - bina\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3249 - binary_accuracy: 0.6178\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3295 - binary_accuracy: 0.6166\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3278 - binary_accuracy: 0.6192\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3277 - binary_accuracy: 0.6195\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3304 - binary_accuracy: 0.6149\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3264 - binary_accuracy: 0.6186\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3289 - binary_accuracy: 0.6177\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3240 - binary_accuracy: 0.6194\n",
      "Epoch 20/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3197 - binary_accuracy: 0.6184\n",
      "Epoch 21/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3234 - binary_accuracy: 0.6220\n",
      "Epoch 22/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3293 - binary_accuracy: 0.6224\n",
      "Epoch 23/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3242 - binary_accuracy: 0.6179\n",
      "Epoch 24/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3233 - binary_accuracy: 0.6195 1s - loss: 0.3227 -\n",
      "Epoch 25/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3217 - binary_accuracy: 0.6266\n",
      "60/60 [==============================] - 2s 33ms/step - loss: 3.2155 - binary_accuracy: 0.5921\n",
      "Epoch 1/25\n",
      "1523/1523 [==============================] - 40s 26ms/step - loss: 0.3237 - binary_accuracy: 0.6207\n",
      "Epoch 2/25\n",
      "1523/1523 [==============================] - 41s 27ms/step - loss: 0.3252 - binary_accuracy: 0.6209\n",
      "Epoch 3/25\n",
      "1523/1523 [==============================] - 42s 28ms/step - loss: 0.3289 - binary_accuracy: 0.6225\n",
      "Epoch 4/25\n",
      "1523/1523 [==============================] - 41s 27ms/step - loss: 0.3250 - binary_accuracy: 0.6224\n",
      "Epoch 5/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3209 - binary_accuracy: 0.6208\n",
      "Epoch 6/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3197 - binary_accuracy: 0.6255\n",
      "Epoch 7/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3311 - binary_accuracy: 0.6150\n",
      "Epoch 8/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3222 - binary_accuracy: 0.6212\n",
      "Epoch 9/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3198 - binary_accuracy: 0.6205\n",
      "Epoch 10/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3182 - binary_accuracy: 0.6242\n",
      "Epoch 11/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3167 - binary_accuracy: 0.6216 1s - loss\n",
      "Epoch 12/25\n",
      "1523/1523 [==============================] - 37s 24ms/step - loss: 0.3202 - binary_accuracy: 0.6209\n",
      "Epoch 13/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3225 - binary_accuracy: 0.6224\n",
      "Epoch 14/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3217 - binary_accuracy: 0.6217\n",
      "Epoch 15/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3179 - binary_accuracy: 0.6269\n",
      "Epoch 16/25\n",
      "1523/1523 [==============================] - 37s 25ms/step - loss: 0.3203 - binary_accuracy: 0.6237\n",
      "Epoch 17/25\n",
      "1523/1523 [==============================] - 38s 25ms/step - loss: 0.3206 - binary_accuracy: 0.6190\n",
      "Epoch 18/25\n",
      "1523/1523 [==============================] - 39s 25ms/step - loss: 0.3164 - binary_accuracy: 0.6262\n",
      "Epoch 19/25\n",
      "1523/1523 [==============================] - 39s 26ms/step - loss: 0.3177 - binary_accuracy: 0.6246\n",
      "Epoch 20/25\n",
      " 317/1523 [=====>........................] - ETA: 31s - loss: 0.3134 - binary_accuracy: 0.6170"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4dce37f082bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     history = model.fit(data_fin_train,label_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m               batch_size=5, epochs=25)\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fin_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    history = model.fit(data_fin_train,label_train,\n",
    "              batch_size=5, epochs=25)\n",
    "    model.evaluate(data_fin_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_Deep_Conv_Net_10Channel_RestData_Included.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_Deep_Conv_Net_10Channel_RestData_Included.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
