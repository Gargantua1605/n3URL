{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prakhar n Sankalp\n",
    "right = np.loadtxt(\"right_data.txt\")\n",
    "right_C_1=np.loadtxt(\"right_data_C_1.txt\")\n",
    "right_C_3=np.loadtxt(\"right_data_C_3.txt\")\n",
    "right_CP_1 = np.loadtxt(\"right_data_CP_1.txt\")\n",
    "right_CP_3 = np.loadtxt(\"right_data_CP_3.txt\")\n",
    "left = np.loadtxt(\"left_data.txt\")\n",
    "left_C_1=np.loadtxt(\"left_data_C_1.txt\")\n",
    "left_C_3=np.loadtxt(\"left_data_C_3.txt\")\n",
    "left_CP_1 = np.loadtxt(\"left_data_CP_1.txt\")\n",
    "left_CP_3 = np.loadtxt(\"left_data_CP_3.txt\")\n",
    "\n",
    "right_reshaped = np.reshape(right, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_reshaped = np.reshape(left, (left.shape[0], left.shape[1] // 2, 2))\n",
    "right_C_1_reshaped = np.reshape(right_C_1, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_C_1_reshaped = np.reshape(left_C_1, (left.shape[0], left.shape[1] // 2, 2))\n",
    "right_C_3_reshaped = np.reshape(right_C_3, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_C_3_reshaped = np.reshape(left_C_3, (left.shape[0], left.shape[1] // 2, 2))\n",
    "right_CP_1_reshaped = np.reshape(right_CP_1, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_CP_1_reshaped = np.reshape(left_CP_1, (left.shape[0], left.shape[1] // 2, 2))\n",
    "right_CP_3_reshaped = np.reshape(right_CP_3, (right.shape[0], right.shape[1] // 2, 2))\n",
    "left_CP_3_reshaped = np.reshape(left_CP_3, (left.shape[0], left.shape[1] // 2, 2))\n",
    "\n",
    "\n",
    "right_label = np.zeros((right.shape[0], 2))\n",
    "right_label[:,0] = 1\n",
    "left_label = np.zeros((left.shape[0], 2))\n",
    "left_label[:, 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "right_train=right_reshaped[:int(0.8*2352)]\n",
    "right_C_1_train=right_C_1_reshaped[:int(0.8*2352)]\n",
    "right_C_3_train=right_C_3_reshaped[:int(0.8*2352)]\n",
    "right_CP_1_train=right_CP_1_reshaped[:int(0.8*2352)]\n",
    "right_CP_3_train=right_CP_3_reshaped[:int(0.8*2352)]\n",
    "\n",
    "right_test=right_reshaped[int(0.8*2352):]\n",
    "right_C_1_test=right_C_1_reshaped[int(0.8*2352):]\n",
    "right_C_3_test=right_C_3_reshaped[int(0.8*2352):]\n",
    "right_CP_1_test=right_CP_1_reshaped[int(0.8*2352):]\n",
    "right_CP_3_test=right_CP_3_reshaped[int(0.8*2352):]\n",
    "\n",
    "\n",
    "right_label_train=right_label[:int(0.8*2352)]\n",
    "right_label_test=right_label[int(0.8*2352):]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "left_train=left_reshaped[:int(0.8*2396)]\n",
    "left_C_1_train=left_C_1_reshaped[:int(0.8*2396)]\n",
    "left_C_3_train=left_C_3_reshaped[:int(0.8*2396)]\n",
    "left_CP_1_train=left_CP_1_reshaped[:int(0.8*2396)]\n",
    "left_CP_3_train=left_CP_3_reshaped[:int(0.8*2396)]\n",
    "\n",
    "left_test=left_reshaped[int(0.8*2396):]\n",
    "left_C_1_test=left_C_1_reshaped[int(0.8*2396):]\n",
    "left_C_3_test=left_C_3_reshaped[int(0.8*2396):]\n",
    "left_CP_1_test=left_CP_1_reshaped[int(0.8*2396):]\n",
    "left_CP_3_test=left_CP_3_reshaped[int(0.8*2396):]\n",
    "\n",
    "\n",
    "\n",
    "left_label_train=left_label[:int(0.8*2396)]\n",
    "left_label_test=left_label[int(0.8*2396):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3797, 640, 10)\n",
      "(3797, 2)\n",
      "(951, 640, 10)\n"
     ]
    }
   ],
   "source": [
    "data_train=np.concatenate((right_train, left_train), axis = 0)\n",
    "data_train_C_1= np.concatenate((right_C_1_train, left_C_1_train), axis = 0)\n",
    "data_train_C_3=np.concatenate((right_C_3_train, left_C_3_train), axis = 0)\n",
    "data_train_CP_1= np.concatenate((right_CP_1_train, left_CP_1_train), axis = 0)\n",
    "data_train_CP_3=np.concatenate((right_CP_3_train, left_CP_3_train), axis = 0)\n",
    "data_final_train=np.concatenate((data_train,data_train_C_1,data_train_C_3, data_train_CP_1, data_train_CP_3), axis = 2)\n",
    "\n",
    "data_test=np.concatenate((right_test, left_test), axis = 0)\n",
    "data_test_C_1= np.concatenate((right_C_1_test, left_C_1_test), axis = 0)\n",
    "data_test_C_3=np.concatenate((right_C_3_test, left_C_3_test), axis = 0)\n",
    "data_test_CP_1= np.concatenate((right_CP_1_test, left_CP_1_test), axis = 0)\n",
    "data_test_CP_3=np.concatenate((right_CP_3_test, left_CP_3_test), axis = 0)\n",
    "data_final_test=np.concatenate((data_test,data_test_C_1,data_test_C_3, data_test_CP_1, data_test_CP_3), axis = 2)\n",
    "\n",
    "label_train = np.concatenate((right_label_train, left_label_train), axis = 0)\n",
    "label_test = np.concatenate((right_label_test, left_label_test), axis = 0)\n",
    "\n",
    "print(data_final_train.shape)\n",
    "print(label_train.shape)\n",
    "\n",
    "print(data_final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize_1= np.arange(0, data_final_train.shape[0], 1)\n",
    "randomize_1 = np.random.permutation(randomize_1)\n",
    "\n",
    "randomize_2= np.arange(0, data_final_test.shape[0], 1)\n",
    "randomize_2 = np.random.permutation(randomize_2)\n",
    "\n",
    "data_final_train = data_final_train[randomize_1]\n",
    "label_train = label_train[randomize_1]\n",
    "data_final_test = data_final_test[randomize_2]\n",
    "label_test = label_test[randomize_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "def new_model(nb_classes, Chans, Samples, dropoutRate = 0.5):\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as tfl\n",
    "model = new_model(2, 10, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 640, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 10, 636, 25)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 636, 25)        6275      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 636, 25)        100       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 636, 25)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 318, 25)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 318, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 314, 50)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 314, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 314, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 157, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 157, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 153, 100)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 153, 100)       400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 153, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 76, 100)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 76, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 72, 200)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 72, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 72, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 36, 200)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 36, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 14402     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 153,927\n",
      "Trainable params: 153,177\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=keras.losses.BinaryCrossentropy(), metrics=keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3797, 10, 640)\n"
     ]
    }
   ],
   "source": [
    "data_fin_train = data_final_train[0].T\n",
    "data_fin_test = data_final_test[0].T\n",
    "data_fin_train = np.concatenate((np.array([data_fin_train]), np.array([data_final_train[1].T])), axis = 0)\n",
    "data_fin_test = np.concatenate((np.array([data_fin_test]), np.array([data_final_test[1].T])), axis = 0)\n",
    "for i in data_final_train[2:]:\n",
    "    data_fin_train = np.concatenate((np.array(data_fin_train), np.array([i.T])), axis = 0)\n",
    "for j in data_final_test[2:]:    \n",
    "    data_fin_test = np.concatenate((np.array(data_fin_test), np.array([j.T])), axis = 0)\n",
    "print(data_fin_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "760/760 [==============================] - 23s 28ms/step - loss: 0.7505 - binary_accuracy: 0.4995\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.7204 - binary_accuracy: 0.5375\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.7264 - binary_accuracy: 0.5236\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.7122 - binary_accuracy: 0.5573\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.7027 - binary_accuracy: 0.5718\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 23s 31ms/step - loss: 0.6939 - binary_accuracy: 0.5994\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6770 - binary_accuracy: 0.5959\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6767 - binary_accuracy: 0.6048 1s - loss: 0.6771 -\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 23s 30ms/step - loss: 0.6664 - binary_accuracy: 0.6309\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6549 - binary_accuracy: 0.6443\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6664 - binary_accuracy: 0.6390\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6489 - binary_accuracy: 0.6495\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6445 - binary_accuracy: 0.6698\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6352 - binary_accuracy: 0.6619\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6387 - binary_accuracy: 0.6612 1s - loss: 0.6391 -\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6428 - binary_accuracy: 0.6619\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6299 - binary_accuracy: 0.6847\n",
      "Epoch 18/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6397 - binary_accuracy: 0.6624\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6394 - binary_accuracy: 0.6604\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6346 - binary_accuracy: 0.6577\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6189 - binary_accuracy: 0.6721\n",
      "Epoch 22/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6243 - binary_accuracy: 0.6692\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6229 - binary_accuracy: 0.6823\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6254 - binary_accuracy: 0.6736\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6213 - binary_accuracy: 0.6706\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.6158 - binary_accuracy: 0.7056\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6136 - binary_accuracy: 0.6840\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6111 - binary_accuracy: 0.6895\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6173 - binary_accuracy: 0.6797\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 24s 31ms/step - loss: 0.6170 - binary_accuracy: 0.6829\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6017 - binary_accuracy: 0.7011\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.6094 - binary_accuracy: 0.6929\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.6042 - binary_accuracy: 0.6963\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.6070 - binary_accuracy: 0.6887\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.6099 - binary_accuracy: 0.6850\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.6045 - binary_accuracy: 0.6916\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6091 - binary_accuracy: 0.6842\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.6076 - binary_accuracy: 0.6890\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6112 - binary_accuracy: 0.6919\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.6118 - binary_accuracy: 0.6876\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.6022 - binary_accuracy: 0.7021 0s - loss: 0.6032 - binary_accu\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6058 - binary_accuracy: 0.6990\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5997 - binary_accuracy: 0.6977\n",
      "Epoch 18/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5982 - binary_accuracy: 0.6966\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6016 - binary_accuracy: 0.6924\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.6039 - binary_accuracy: 0.6990\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.6055 - binary_accuracy: 0.6898\n",
      "Epoch 22/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5973 - binary_accuracy: 0.7021\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.6035 - binary_accuracy: 0.6927\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5985 - binary_accuracy: 0.6908\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5975 - binary_accuracy: 0.6977\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 0.6503 - binary_accuracy: 0.7087\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.6015 - binary_accuracy: 0.6905\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5940 - binary_accuracy: 0.6974\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5989 - binary_accuracy: 0.6982\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 23s 30ms/step - loss: 0.5950 - binary_accuracy: 0.7090 3s - loss: 0.5951 - binary_accurac\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 23s 30ms/step - loss: 0.5898 - binary_accuracy: 0.7040 1s - loss: 0.5878 - binary_accuracy: 0.704 - ETA: 1s - loss: 0.5888 - bin\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5970 - binary_accuracy: 0.6998\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5955 - binary_accuracy: 0.6903 0s - loss: 0.5968 - binary_accuracy: 0\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5911 - binary_accuracy: 0.7069\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.5937 - binary_accuracy: 0.6987\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5921 - binary_accuracy: 0.6977\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5899 - binary_accuracy: 0.7035\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5999 - binary_accuracy: 0.7058\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5888 - binary_accuracy: 0.6984\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5856 - binary_accuracy: 0.7124\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5887 - binary_accuracy: 0.7045\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5924 - binary_accuracy: 0.6995\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5836 - binary_accuracy: 0.7011\n",
      "Epoch 18/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5916 - binary_accuracy: 0.7013\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5795 - binary_accuracy: 0.7119\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5871 - binary_accuracy: 0.7077\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5821 - binary_accuracy: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5759 - binary_accuracy: 0.7135\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5840 - binary_accuracy: 0.7124\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.5797 - binary_accuracy: 0.7100\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5846 - binary_accuracy: 0.7119\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.6087 - binary_accuracy: 0.7203\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5804 - binary_accuracy: 0.7190\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5798 - binary_accuracy: 0.7040\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5789 - binary_accuracy: 0.7121\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5770 - binary_accuracy: 0.7108\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5759 - binary_accuracy: 0.7121\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5776 - binary_accuracy: 0.7171\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5709 - binary_accuracy: 0.7211\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5751 - binary_accuracy: 0.7142\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5723 - binary_accuracy: 0.7177\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.5691 - binary_accuracy: 0.7177\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5732 - binary_accuracy: 0.7161\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5686 - binary_accuracy: 0.7077\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5723 - binary_accuracy: 0.7137\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5706 - binary_accuracy: 0.7100 0s - loss: 0.5709 - binary_accura\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5698 - binary_accuracy: 0.7208\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5641 - binary_accuracy: 0.7195\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5670 - binary_accuracy: 0.7190\n",
      "Epoch 18/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5662 - binary_accuracy: 0.7256\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5680 - binary_accuracy: 0.7161\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5688 - binary_accuracy: 0.7198\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5719 - binary_accuracy: 0.7108\n",
      "Epoch 22/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5613 - binary_accuracy: 0.7221\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5633 - binary_accuracy: 0.7258\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5675 - binary_accuracy: 0.7187\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5571 - binary_accuracy: 0.7221\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.5791 - binary_accuracy: 0.7298\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5704 - binary_accuracy: 0.7135\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5625 - binary_accuracy: 0.7187\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5595 - binary_accuracy: 0.7229\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5644 - binary_accuracy: 0.7187\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5623 - binary_accuracy: 0.7137\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5614 - binary_accuracy: 0.7235\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5586 - binary_accuracy: 0.7208\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5598 - binary_accuracy: 0.7269\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 20s 26ms/step - loss: 0.5588 - binary_accuracy: 0.7214\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5627 - binary_accuracy: 0.7235\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5513 - binary_accuracy: 0.7245\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5649 - binary_accuracy: 0.7216\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5617 - binary_accuracy: 0.7253\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5551 - binary_accuracy: 0.7293\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5629 - binary_accuracy: 0.7243\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5503 - binary_accuracy: 0.7303 2\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5494 - binary_accuracy: 0.7361\n",
      "Epoch 18/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5562 - binary_accuracy: 0.7272\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5520 - binary_accuracy: 0.7227\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5588 - binary_accuracy: 0.7253\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5568 - binary_accuracy: 0.7203\n",
      "Epoch 22/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5536 - binary_accuracy: 0.7287\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5435 - binary_accuracy: 0.7348\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5549 - binary_accuracy: 0.7235\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5531 - binary_accuracy: 0.7264\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.5672 - binary_accuracy: 0.7277\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5511 - binary_accuracy: 0.7337\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5515 - binary_accuracy: 0.7287\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5514 - binary_accuracy: 0.7366\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5489 - binary_accuracy: 0.7337\n",
      "Epoch 5/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5399 - binary_accuracy: 0.7327\n",
      "Epoch 6/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5500 - binary_accuracy: 0.7258\n",
      "Epoch 7/25\n",
      "760/760 [==============================] - 22s 28ms/step - loss: 0.5410 - binary_accuracy: 0.7343\n",
      "Epoch 8/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5430 - binary_accuracy: 0.7411\n",
      "Epoch 9/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5446 - binary_accuracy: 0.7343\n",
      "Epoch 10/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5484 - binary_accuracy: 0.7256\n",
      "Epoch 11/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5394 - binary_accuracy: 0.7361\n",
      "Epoch 12/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5442 - binary_accuracy: 0.7366\n",
      "Epoch 13/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5445 - binary_accuracy: 0.7295\n",
      "Epoch 14/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5399 - binary_accuracy: 0.7411\n",
      "Epoch 15/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5418 - binary_accuracy: 0.7380\n",
      "Epoch 16/25\n",
      "760/760 [==============================] - 21s 28ms/step - loss: 0.5384 - binary_accuracy: 0.7358\n",
      "Epoch 17/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5435 - binary_accuracy: 0.7353 1s - loss: 0.5439 - b\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5357 - binary_accuracy: 0.7340\n",
      "Epoch 19/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5346 - binary_accuracy: 0.7351\n",
      "Epoch 20/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5337 - binary_accuracy: 0.7424\n",
      "Epoch 21/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5422 - binary_accuracy: 0.7353\n",
      "Epoch 22/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5486 - binary_accuracy: 0.7327\n",
      "Epoch 23/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5386 - binary_accuracy: 0.7401\n",
      "Epoch 24/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5294 - binary_accuracy: 0.7453\n",
      "Epoch 25/25\n",
      "760/760 [==============================] - 20s 27ms/step - loss: 0.5308 - binary_accuracy: 0.7416\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.6296 - binary_accuracy: 0.7256\n",
      "Epoch 1/25\n",
      "760/760 [==============================] - 22s 29ms/step - loss: 0.5329 - binary_accuracy: 0.7406\n",
      "Epoch 2/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5380 - binary_accuracy: 0.7448\n",
      "Epoch 3/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5348 - binary_accuracy: 0.7459\n",
      "Epoch 4/25\n",
      "760/760 [==============================] - 21s 27ms/step - loss: 0.5299 - binary_accuracy: 0.7437\n",
      "Epoch 5/25\n",
      "648/760 [========================>.....] - ETA: 3s - loss: 0.5275 - binary_accuracy: 0.7491- ETA: 4s - loss: 0.5334 - bi"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0d1be69bf26b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     history = model.fit(data_fin_train,label_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m               batch_size=5, epochs=25)\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fin_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    history = model.fit(data_fin_train,label_train,\n",
    "              batch_size=5, epochs=25)\n",
    "    model.evaluate(data_fin_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"Deep_Conv_Net_10Channel_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Deep_Conv_Net_10Channel_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Deep_Conv_Net_10Channel_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 37ms/step - loss: 0.5423 - binary_accuracy: 0.7508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5423038601875305, 0.7507886290550232]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_fin_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
